{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "61241717-8bec-49e1-a210-ac1374f1841f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import argparse\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import voxelmorph as vxm\n",
    "import pdb\n",
    "\n",
    "\n",
    "# disable eager execution\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "\n",
    "\n",
    "# parse the commandline\n",
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "# data organization parameters\n",
    "parser.add_argument('--img-list', default='list.txt', help='line-seperated list of training files')\n",
    "parser.add_argument('--img-prefix', help='optional input image file prefix')\n",
    "parser.add_argument('--img-suffix', help='optional input image file suffix')\n",
    "parser.add_argument('--atlas', help='optional atlas filename')\n",
    "parser.add_argument('--model-dir', default='models',\n",
    "                    help='model output directory (default: models)')\n",
    "parser.add_argument('--multichannel', action='store_true',\n",
    "                    help='specify that data has multiple channels')\n",
    "\n",
    "# training parameters\n",
    "parser.add_argument('--gpu', default='0', help='GPU ID numbers (default: 0)')\n",
    "parser.add_argument('--batch-size', type=int, default=1, help='batch size (default: 1)')\n",
    "parser.add_argument('--epochs', type=int, default=1500,\n",
    "                    help='number of training epochs (default: 1500)')\n",
    "parser.add_argument('--steps-per-epoch', type=int, default=100,\n",
    "                    help='frequency of model saves (default: 100)')\n",
    "parser.add_argument('--load-weights', help='optional weights file to initialize with')\n",
    "parser.add_argument('--initial-epoch', type=int, default=0,\n",
    "                    help='initial epoch number (default: 0)')\n",
    "parser.add_argument('--lr', type=float, default=1e-4, help='learning rate (default: 1e-4)')\n",
    "\n",
    "# network architecture parameters\n",
    "parser.add_argument('--enc', type=int, nargs='+',\n",
    "                    help='list of unet encoder filters (default: 16 32 32 32)')\n",
    "parser.add_argument('--dec', type=int, nargs='+',\n",
    "                    help='list of unet decorder filters (default: 32 32 32 32 32 16 16)')\n",
    "parser.add_argument('--int-steps', type=int, default=7,\n",
    "                    help='number of integration steps (default: 7)')\n",
    "parser.add_argument('--int-downsize', type=int, default=2,\n",
    "                    help='flow downsample factor for integration (default: 2)')\n",
    "parser.add_argument('--use-probs', action='store_true', help='enable probabilities')\n",
    "parser.add_argument('--bidir', action='store_true', help='enable bidirectional cost function')\n",
    "\n",
    "# loss hyperparameters\n",
    "parser.add_argument('--image-loss', default='mse',\n",
    "                    help='image reconstruction loss - can be mse or ncc (default: mse)')\n",
    "parser.add_argument('--lambda', type=float, dest='lambda_weight', default=0.01,\n",
    "                    help='weight of gradient or KL loss (default: 0.01)')\n",
    "parser.add_argument('--kl-lambda', type=float, default=10,\n",
    "                    help='prior lambda regularization for KL loss (default: 10)')\n",
    "parser.add_argument('--legacy-image-sigma', dest='image_sigma', type=float, default=1.0,\n",
    "                    help='image noise parameter for miccai 2018 network (recommended value is 0.02 when --use-probs is enabled)')  # nopep8\n",
    "args = parser.parse_args(args=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9ac8ae93-11fa-4d2b-aea9-45683782a57c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# load and prepare training data\n",
    "train_files = vxm.py.utils.read_file_list(args.img_list, prefix=args.img_prefix,\n",
    "                                          suffix=args.img_suffix)\n",
    "assert len(train_files) > 0, 'Could not find any training data.'\n",
    "\n",
    "# no need to append an extra feature axis if data is multichannel\n",
    "add_feat_axis = not args.multichannel\n",
    "\n",
    "if args.atlas:\n",
    "    # scan-to-atlas generator\n",
    "    atlas = vxm.py.utils.load_volfile(args.atlas, np_var='vol',\n",
    "                                      add_batch_axis=True, add_feat_axis=add_feat_axis)\n",
    "    generator = vxm.generators.scan_to_atlas(train_files, atlas,\n",
    "                                             batch_size=args.batch_size,\n",
    "                                             bidir=args.bidir,\n",
    "                                             add_feat_axis=add_feat_axis)\n",
    "else:\n",
    "    # scan-to-scan generator\n",
    "    generator = vxm.generators.scan_to_scan(\n",
    "        train_files, batch_size=args.batch_size, bidir=args.bidir, add_feat_axis=add_feat_axis)\n",
    "\n",
    "# extract shape and number of features from sampled input\n",
    "sample_shape = next(generator)[0][0].shape\n",
    "inshape = sample_shape[1:-1]\n",
    "nfeats = sample_shape[-1]\n",
    "\n",
    "# prepare model folder\n",
    "model_dir = args.model_dir\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "# tensorflow device handling\n",
    "device, nb_devices = vxm.tf.utils.setup_device(args.gpu)\n",
    "assert np.mod(args.batch_size, nb_devices) == 0, \\\n",
    "    'Batch size (%d) should be a multiple of the nr of gpus (%d)' % (args.batch_size, nb_devices)\n",
    "\n",
    "# unet architecture\n",
    "enc_nf = args.enc if args.enc else [16, 32, 32, 32]\n",
    "dec_nf = args.dec if args.dec else [32, 32, 32, 32, 32, 16, 16]\n",
    "\n",
    "# prepare model checkpoint save path\n",
    "save_filename = os.path.join(model_dir, '{epoch:04d}.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a2780a87-0906-42a9-9963-e83636360db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load and prepare training data\n",
    "train_files = vxm.py.utils.read_file_list(args.img_list, prefix=args.img_prefix,\n",
    "                                          suffix=args.img_suffix)\n",
    "assert len(train_files) > 0, 'Could not find any training data.'\n",
    "\n",
    "# no need to append an extra feature axis if data is multichannel\n",
    "add_feat_axis = not args.multichannel\n",
    "\n",
    "if args.atlas:\n",
    "    # scan-to-atlas generator\n",
    "    atlas = vxm.py.utils.load_volfile(args.atlas, np_var='vol',\n",
    "                                      add_batch_axis=True, add_feat_axis=add_feat_axis)\n",
    "    generator = vxm.generators.scan_to_atlas(train_files, atlas,\n",
    "                                             batch_size=args.batch_size,\n",
    "                                             bidir=args.bidir,\n",
    "                                             add_feat_axis=add_feat_axis)\n",
    "else:\n",
    "    # scan-to-scan generator\n",
    "    generator = vxm.generators.scan_to_scan(\n",
    "        train_files, batch_size=args.batch_size, bidir=args.bidir, add_feat_axis=add_feat_axis)\n",
    "\n",
    "# extract shape and number of features from sampled input\n",
    "sample_shape = next(generator)[0][0].shape\n",
    "inshape = sample_shape[1:-1]\n",
    "nfeats = sample_shape[-1]\n",
    "\n",
    "# prepare model folder\n",
    "model_dir = args.model_dir\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "# tensorflow device handling\n",
    "device, nb_devices = vxm.tf.utils.setup_device(args.gpu)\n",
    "assert np.mod(args.batch_size, nb_devices) == 0, \\\n",
    "    'Batch size (%d) should be a multiple of the nr of gpus (%d)' % (args.batch_size, nb_devices)\n",
    "\n",
    "# unet architecture\n",
    "enc_nf = args.enc if args.enc else [16, 32, 32, 32]\n",
    "dec_nf = args.dec if args.dec else [32, 32, 32, 32, 32, 16, 16]\n",
    "\n",
    "# prepare model checkpoint save path\n",
    "save_filename = os.path.join(model_dir, '{epoch:04d}.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "74e3da24-9050-43a6-8ba8-2ce0d06544bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(512, 512, 96)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0e792297-2ab4-487a-af29-b5dfe43df38c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_26\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "vxm_dense_source_input (InputLa [(None, 512, 512, 96 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "vxm_dense_target_input (InputLa [(None, 512, 512, 96 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "vxm_dense_unet_input_concat (Co (None, 512, 512, 96, 0           vxm_dense_source_input[0][0]     \n",
      "                                                                 vxm_dense_target_input[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "vxm_dense_unet_enc_conv_0_0 (Co (None, 512, 512, 96, 880         vxm_dense_unet_input_concat[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "vxm_dense_unet_enc_conv_0_0_act (None, 512, 512, 96, 0           vxm_dense_unet_enc_conv_0_0[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "vxm_dense_unet_enc_pooling_0 (M (None, 256, 256, 48, 0           vxm_dense_unet_enc_conv_0_0_activ\n",
      "__________________________________________________________________________________________________\n",
      "vxm_dense_unet_enc_conv_1_0 (Co (None, 256, 256, 48, 13856       vxm_dense_unet_enc_pooling_0[0][0\n",
      "__________________________________________________________________________________________________\n",
      "vxm_dense_unet_enc_conv_1_0_act (None, 256, 256, 48, 0           vxm_dense_unet_enc_conv_1_0[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "vxm_dense_unet_enc_pooling_1 (M (None, 128, 128, 24, 0           vxm_dense_unet_enc_conv_1_0_activ\n",
      "__________________________________________________________________________________________________\n",
      "vxm_dense_unet_enc_conv_2_0 (Co (None, 128, 128, 24, 27680       vxm_dense_unet_enc_pooling_1[0][0\n",
      "__________________________________________________________________________________________________\n",
      "vxm_dense_unet_enc_conv_2_0_act (None, 128, 128, 24, 0           vxm_dense_unet_enc_conv_2_0[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "vxm_dense_unet_enc_pooling_2 (M (None, 64, 64, 12, 3 0           vxm_dense_unet_enc_conv_2_0_activ\n",
      "__________________________________________________________________________________________________\n",
      "vxm_dense_unet_enc_conv_3_0 (Co (None, 64, 64, 12, 3 27680       vxm_dense_unet_enc_pooling_2[0][0\n",
      "__________________________________________________________________________________________________\n",
      "vxm_dense_unet_enc_conv_3_0_act (None, 64, 64, 12, 3 0           vxm_dense_unet_enc_conv_3_0[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "vxm_dense_unet_enc_pooling_3 (M (None, 32, 32, 6, 32 0           vxm_dense_unet_enc_conv_3_0_activ\n",
      "__________________________________________________________________________________________________\n",
      "vxm_dense_unet_dec_conv_3_0 (Co (None, 32, 32, 6, 32 27680       vxm_dense_unet_enc_pooling_3[0][0\n",
      "__________________________________________________________________________________________________\n",
      "vxm_dense_unet_dec_conv_3_0_act (None, 32, 32, 6, 32 0           vxm_dense_unet_dec_conv_3_0[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "vxm_dense_unet_dec_upsample_3 ( (None, 64, 64, 12, 3 0           vxm_dense_unet_dec_conv_3_0_activ\n",
      "__________________________________________________________________________________________________\n",
      "vxm_dense_unet_dec_upsample_3_c (None, 64, 64, 12, 6 0           vxm_dense_unet_dec_upsample_3[0][\n",
      "                                                                 vxm_dense_unet_enc_conv_3_0_activ\n",
      "__________________________________________________________________________________________________\n",
      "vxm_dense_unet_dec_conv_2_0 (Co (None, 64, 64, 12, 3 55328       vxm_dense_unet_dec_upsample_3_con\n",
      "__________________________________________________________________________________________________\n",
      "vxm_dense_unet_dec_conv_2_0_act (None, 64, 64, 12, 3 0           vxm_dense_unet_dec_conv_2_0[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "vxm_dense_unet_dec_upsample_2 ( (None, 128, 128, 24, 0           vxm_dense_unet_dec_conv_2_0_activ\n",
      "__________________________________________________________________________________________________\n",
      "vxm_dense_unet_dec_upsample_2_c (None, 128, 128, 24, 0           vxm_dense_unet_dec_upsample_2[0][\n",
      "                                                                 vxm_dense_unet_enc_conv_2_0_activ\n",
      "__________________________________________________________________________________________________\n",
      "vxm_dense_unet_dec_conv_1_0 (Co (None, 128, 128, 24, 55328       vxm_dense_unet_dec_upsample_2_con\n",
      "__________________________________________________________________________________________________\n",
      "vxm_dense_unet_dec_conv_1_0_act (None, 128, 128, 24, 0           vxm_dense_unet_dec_conv_1_0[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "vxm_dense_unet_dec_upsample_1 ( (None, 256, 256, 48, 0           vxm_dense_unet_dec_conv_1_0_activ\n",
      "__________________________________________________________________________________________________\n",
      "vxm_dense_unet_dec_upsample_1_c (None, 256, 256, 48, 0           vxm_dense_unet_dec_upsample_1[0][\n",
      "                                                                 vxm_dense_unet_enc_conv_1_0_activ\n",
      "__________________________________________________________________________________________________\n",
      "vxm_dense_unet_dec_conv_0_0 (Co (None, 256, 256, 48, 55328       vxm_dense_unet_dec_upsample_1_con\n",
      "__________________________________________________________________________________________________\n",
      "vxm_dense_unet_dec_conv_0_0_act (None, 256, 256, 48, 0           vxm_dense_unet_dec_conv_0_0[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "vxm_dense_unet_dec_upsample_0 ( (None, 512, 512, 96, 0           vxm_dense_unet_dec_conv_0_0_activ\n",
      "__________________________________________________________________________________________________\n",
      "vxm_dense_unet_dec_upsample_0_c (None, 512, 512, 96, 0           vxm_dense_unet_dec_upsample_0[0][\n",
      "                                                                 vxm_dense_unet_enc_conv_0_0_activ\n",
      "__________________________________________________________________________________________________\n",
      "vxm_dense_unet_dec_final_conv_0 (None, 512, 512, 96, 41504       vxm_dense_unet_dec_upsample_0_con\n",
      "__________________________________________________________________________________________________\n",
      "vxm_dense_unet_dec_final_conv_0 (None, 512, 512, 96, 0           vxm_dense_unet_dec_final_conv_0[0\n",
      "__________________________________________________________________________________________________\n",
      "vxm_dense_unet_dec_final_conv_1 (None, 512, 512, 96, 13840       vxm_dense_unet_dec_final_conv_0_a\n",
      "__________________________________________________________________________________________________\n",
      "vxm_dense_unet_dec_final_conv_1 (None, 512, 512, 96, 0           vxm_dense_unet_dec_final_conv_1[0\n",
      "__________________________________________________________________________________________________\n",
      "vxm_dense_unet_dec_final_conv_2 (None, 512, 512, 96, 6928        vxm_dense_unet_dec_final_conv_1_a\n",
      "__________________________________________________________________________________________________\n",
      "vxm_dense_unet_dec_final_conv_2 (None, 512, 512, 96, 0           vxm_dense_unet_dec_final_conv_2[0\n",
      "__________________________________________________________________________________________________\n",
      "vxm_dense_flow (Conv3D)         (None, 512, 512, 96, 1299        vxm_dense_unet_dec_final_conv_2_a\n",
      "__________________________________________________________________________________________________\n",
      "vxm_dense_flow_resize (RescaleT (None, 256, 256, 48, 0           vxm_dense_flow[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "vxm_dense_flow_int (VecInt)     (None, 256, 256, 48, 0           vxm_dense_flow_resize[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "vxm_dense_diffflow (RescaleTran (None, 512, 512, 96, 0           vxm_dense_flow_int[0][0]         \n",
      "==================================================================================================\n",
      "Total params: 327,331\n",
      "Trainable params: 327,331\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# inshape = (160, 192, 224)\n",
    "model = vxm.networks.VxmDense(\n",
    "    inshape=inshape,\n",
    "    nb_unet_features=[enc_nf, dec_nf],\n",
    "    bidir=args.bidir,\n",
    "    use_probs=args.use_probs,\n",
    "    int_steps=args.int_steps,\n",
    "    int_resolution=args.int_downsize,\n",
    "    src_feats=nfeats,\n",
    "    trg_feats=nfeats\n",
    ")\n",
    "model.get_registration_model().summary()\n",
    "# for layer in model.layers:\n",
    "    # print(layer.output_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "609c22d9-23fd-42fe-9277-cc9fefd68905",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(None, 256, 256, 16, 1)]\n",
      "[(None, 256, 256, 16, 1)]\n",
      "(None, 256, 256, 16, 2)\n",
      "(None, 256, 256, 16, 16)\n",
      "(None, 256, 256, 16, 16)\n",
      "(None, 128, 128, 8, 16)\n",
      "(None, 128, 128, 8, 32)\n",
      "(None, 128, 128, 8, 32)\n",
      "(None, 64, 64, 4, 32)\n",
      "(None, 64, 64, 4, 32)\n",
      "(None, 64, 64, 4, 32)\n",
      "(None, 32, 32, 2, 32)\n",
      "(None, 32, 32, 2, 32)\n",
      "(None, 32, 32, 2, 32)\n",
      "(None, 16, 16, 1, 32)\n",
      "(None, 16, 16, 1, 32)\n",
      "(None, 16, 16, 1, 32)\n",
      "(None, 32, 32, 2, 32)\n",
      "(None, 32, 32, 2, 64)\n",
      "(None, 32, 32, 2, 32)\n",
      "(None, 32, 32, 2, 32)\n",
      "(None, 64, 64, 4, 32)\n",
      "(None, 64, 64, 4, 64)\n",
      "(None, 64, 64, 4, 32)\n",
      "(None, 64, 64, 4, 32)\n",
      "(None, 128, 128, 8, 32)\n",
      "(None, 128, 128, 8, 64)\n",
      "(None, 128, 128, 8, 32)\n",
      "(None, 128, 128, 8, 32)\n",
      "(None, 256, 256, 16, 32)\n",
      "(None, 256, 256, 16, 48)\n",
      "(None, 256, 256, 16, 32)\n",
      "(None, 256, 256, 16, 32)\n",
      "(None, 256, 256, 16, 16)\n",
      "(None, 256, 256, 16, 16)\n",
      "(None, 256, 256, 16, 16)\n",
      "(None, 256, 256, 16, 16)\n",
      "(None, 256, 256, 16, 3)\n",
      "(None, 128, 128, 8, 3)\n",
      "(None, 128, 128, 8, 3)\n",
      "(None, 256, 256, 16, 3)\n",
      "(None, 256, 256, 16, 1)\n"
     ]
    }
   ],
   "source": [
    "inshape = (256, 256, 16)\n",
    "model = vxm.networks.VxmDense(\n",
    "    inshape=inshape,\n",
    "    nb_unet_features=[enc_nf, dec_nf],\n",
    "    bidir=args.bidir,\n",
    "    use_probs=args.use_probs,\n",
    "    int_steps=args.int_steps,\n",
    "    int_resolution=args.int_downsize,\n",
    "    src_feats=nfeats,\n",
    "    trg_feats=nfeats\n",
    ")\n",
    "# model.get_registration_model().summary()\n",
    "for layer in model.layers:\n",
    "    print(layer.output_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e5f461-7899-4050-b91e-74a79adeda50",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
